{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Dataset:\n\nhttps://www.kaggle.com/aiswaryaramachandran/hindienglish-corpora/download","metadata":{}},{"cell_type":"markdown","source":"### Import Libraries and dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\n\nlines = pd.read_csv(\"/kaggle/input/hindienglish-corpora/Hindi_English_Truncated_Corpus.csv\", encoding='utf-8')\nlines=lines[lines['source']=='ted']\nlines=lines[~pd.isnull(lines['english_sentence'])]\nlines.drop_duplicates(inplace=True)\n# Let us pick any 25000 rows from the dataset\nlines=lines.sample(n=25000,random_state=42)\nlines.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:09.073485Z","iopub.execute_input":"2023-09-21T13:25:09.073828Z","iopub.status.idle":"2023-09-21T13:25:19.204465Z","shell.execute_reply.started":"2023-09-21T13:25:09.073798Z","shell.execute_reply":"2023-09-21T13:25:19.203382Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"(25000, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"For simplicity, I will lowercase all the characters in the dataset:","metadata":{}},{"cell_type":"code","source":"lines['english_sentence'] = lines['english_sentence'].apply(lambda x:x.lower())\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x:x.lower())","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:19.210927Z","iopub.execute_input":"2023-09-21T13:25:19.211254Z","iopub.status.idle":"2023-09-21T13:25:19.255535Z","shell.execute_reply.started":"2023-09-21T13:25:19.211221Z","shell.execute_reply":"2023-09-21T13:25:19.254643Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Now I will remove all the quotes from the data:","metadata":{}},{"cell_type":"code","source":"lines['english_sentence'] = lines['english_sentence'].apply(lambda x:re.sub(\"'\",'',x))\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x:re.sub(\"'\",'',x))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:19.264780Z","iopub.execute_input":"2023-09-21T13:25:19.265497Z","iopub.status.idle":"2023-09-21T13:25:19.349762Z","shell.execute_reply.started":"2023-09-21T13:25:19.265464Z","shell.execute_reply":"2023-09-21T13:25:19.348947Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Now I will remove all the special characters in the data:","metadata":{}},{"cell_type":"code","source":"exclude = set(string.punctuation) # Set of all special characters\n# Remove all the special characters\nlines['english_sentence'] = lines['english_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in exclude))\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in exclude))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:19.350918Z","iopub.execute_input":"2023-09-21T13:25:19.351739Z","iopub.status.idle":"2023-09-21T13:25:19.696002Z","shell.execute_reply.started":"2023-09-21T13:25:19.351707Z","shell.execute_reply":"2023-09-21T13:25:19.695081Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Now I will remove all the numbers and extra spaces from the data:","metadata":{}},{"cell_type":"code","source":"remove_digits = str.maketrans('','',digits)\nlines['english_sentence'] = lines['english_sentence'].apply(lambda x:x.translate(remove_digits))\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x:x.translate(remove_digits))\n\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x:re.sub(\"[२३०८१५७९४६]\", \"\", x))\n\n# remove extra spaces\nlines['english_sentence'] = lines['english_sentence'].apply(lambda x: x.strip())\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: x.strip())\nlines['english_sentence'] = lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: 'START_'+ x + ' _END')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:19.697441Z","iopub.execute_input":"2023-09-21T13:25:19.697884Z","iopub.status.idle":"2023-09-21T13:25:20.155476Z","shell.execute_reply.started":"2023-09-21T13:25:19.697851Z","shell.execute_reply":"2023-09-21T13:25:20.154463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Now as we have cleared the dataset the next thing we need to do is to prepare two sets of vocabularies of Hindi and English:","metadata":{}},{"cell_type":"code","source":"\"\"\"\nGet English and Hindi Vocabulary\n\"\"\"\n\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_hindi_words = set()\nfor hin in lines['hindi_sentence']:\n    for word in hin.split():\n        if word not in all_hindi_words:\n            all_hindi_words.add(word)\nlines['length_eng_sentence'] = lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_hin_sentence'] = lines['hindi_sentence'].apply(lambda x: len(x.split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:20.156792Z","iopub.execute_input":"2023-09-21T13:25:20.157182Z","iopub.status.idle":"2023-09-21T13:25:20.345497Z","shell.execute_reply.started":"2023-09-21T13:25:20.157149Z","shell.execute_reply":"2023-09-21T13:25:20.344480Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Now before training the language translation model we need to set the input and target values:","metadata":{}},{"cell_type":"code","source":"lines = lines[lines['length_eng_sentence']<=20]\nlines = lines[lines['length_hin_sentence']<=20]\nmax_length_src = max(lines['length_hin_sentence'])\nmax_length_tar = max(lines['length_eng_sentence'])\n\ninput_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_hindi_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_hindi_words)\nnum_encoder_tokens, num_encoder_tokens\n\nnum_decoder_tokens += 1 # for zero padding\ninput_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\nreverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\nlines = shuffle(lines)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:20.348774Z","iopub.execute_input":"2023-09-21T13:25:20.349228Z","iopub.status.idle":"2023-09-21T13:25:20.419847Z","shell.execute_reply.started":"2023-09-21T13:25:20.349196Z","shell.execute_reply":"2023-09-21T13:25:20.418899Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Training Model to Translate English to Hindi\n\nNow as we have prepared our dataset let’s train a model for the task of Language translation model. For this task I will first split the data and then we will move forward to train our model:","metadata":{}},{"cell_type":"code","source":"X, y = lines['english_sentence'], lines['hindi_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:25:20.421155Z","iopub.execute_input":"2023-09-21T13:25:20.421615Z","iopub.status.idle":"2023-09-21T13:25:20.441722Z","shell.execute_reply.started":"2023-09-21T13:25:20.421580Z","shell.execute_reply":"2023-09-21T13:25:20.440861Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Now let’s train our language translation model:","metadata":{}},{"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n\nlatent_dim = 300\nencoder_inputs = Input(shape=(None,))\nenc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard 'encoder_outputs' and only keep the states\nencoder_states = [state_h, state_c]\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)\ndec_emb = dec_emb_layer(decoder_inputs)\n\"\"\" We set up our decoder to return full output sequences,\nand to return internal states as well. We don't use the \nreturn states in the training model, but we will use them in inference.\n\"\"\"\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n\"\"\" \nDefine the model that will turn `encoder_input_data` & `decoder_input_data` \ninto `decoder_target_data`\n\"\"\"\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy')\nmodel.summary()\n\ntrain_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 10\n\nmodel.fit_generator(generator= generate_batch(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n                    validation_steps=val_samples//batch_size)\n\nmodel.save_weights('nmt_weights.h5')\n\n# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2 = dec_emb_layer(decoder_inputs)  # Get the embeddings of the decoder sequence\n\n# to predict the next word in the sequence, set the initial states to the states from previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2)  # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n\ndef decode_sequence(input_seq):\n    # Encode the input as state vectors\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character\n    target_seq[0,0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # to simplify, here we assume a batch of size 1\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+ sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character\n        if (sampled_char == '_END' or \n            len(decoded_sentence)>50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1)\n        target_seq = np.zeros((1,1))\n        target_seq[0,0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence\n\ntrain_gen = generate_batch(X_train, y_test, batch_size=1)\nk=-1","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:38:28.759211Z","iopub.execute_input":"2023-09-21T13:38:28.760119Z","iopub.status.idle":"2023-09-21T13:51:00.812536Z","shell.execute_reply.started":"2023-09-21T13:38:28.760079Z","shell.execute_reply":"2023-09-21T13:51:00.811531Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n input_4 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n embedding_2 (Embedding)        (None, None, 300)    4209000     ['input_3[0][0]']                \n                                                                                                  \n embedding_3 (Embedding)        (None, None, 300)    6016500     ['input_4[0][0]']                \n                                                                                                  \n lstm_2 (LSTM)                  [(None, 300),        721200      ['embedding_2[0][0]']            \n                                 (None, 300),                                                     \n                                 (None, 300)]                                                     \n                                                                                                  \n lstm_3 (LSTM)                  [(None, None, 300),  721200      ['embedding_3[0][0]',            \n                                 (None, 300),                     'lstm_2[0][1]',                 \n                                 (None, 300)]                     'lstm_2[0][2]']                 \n                                                                                                  \n dense_1 (Dense)                (None, None, 20055)  6036555     ['lstm_3[0][0]']                 \n                                                                                                  \n==================================================================================================\nTotal params: 17,704,455\nTrainable params: 17,704,455\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_53/1964176042.py:54: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  model.fit_generator(generator= generate_batch(X_train, y_train, batch_size=batch_size),\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n155/155 [==============================] - 81s 470ms/step - loss: 6.9975 - val_loss: 6.4168\nEpoch 2/10\n155/155 [==============================] - 66s 422ms/step - loss: 6.3642 - val_loss: 6.3779\nEpoch 3/10\n155/155 [==============================] - 74s 481ms/step - loss: 6.3263 - val_loss: 6.3667\nEpoch 4/10\n155/155 [==============================] - 66s 430ms/step - loss: 6.2963 - val_loss: 6.3385\nEpoch 5/10\n155/155 [==============================] - 73s 474ms/step - loss: 6.2365 - val_loss: 6.2760\nEpoch 6/10\n155/155 [==============================] - 65s 422ms/step - loss: 6.1666 - val_loss: 6.2220\nEpoch 7/10\n155/155 [==============================] - 73s 472ms/step - loss: 6.1115 - val_loss: 6.1821\nEpoch 8/10\n155/155 [==============================] - 73s 474ms/step - loss: 6.0602 - val_loss: 6.1435\nEpoch 9/10\n155/155 [==============================] - 73s 471ms/step - loss: 6.0032 - val_loss: 6.0917\nEpoch 10/10\n155/155 [==============================] - 72s 470ms/step - loss: 5.9381 - val_loss: 6.0344\n","output_type":"stream"}]},{"cell_type":"markdown","source":"So we have successfully built and trained our model for the task of language translation with Machine Learning. Now let’s see how the model performs by translating a sentence:","metadata":{}},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T13:51:45.431460Z","iopub.execute_input":"2023-09-21T13:51:45.431850Z","iopub.status.idle":"2023-09-21T13:51:48.570359Z","shell.execute_reply.started":"2023-09-21T13:51:45.431817Z","shell.execute_reply":"2023-09-21T13:51:48.569394Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 1s 1s/step\n1/1 [==============================] - 1s 1s/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\nInput English sentence: that there is something called dark matter in the universe\nActual Hindi Translation: इस ब्रह्माण्ड में कुछ ऐसा है जिसे वे श्याम डार्क पदार्थ कहते हैं \nPredicted Hindi Translation:  ये एक एक एक एक साथ के लिए \n","output_type":"stream"}]},{"cell_type":"markdown","source":"Source:\n\nhttps://thecleverprogrammer.com/2020/12/08/language-translation-with-python/","metadata":{}}]}