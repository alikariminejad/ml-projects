{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "https://realpython.com/python-nltk-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick way to download specific resources directly from the console is to pass a list to nltk.download():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /home/ali/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to /home/ali/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/ali/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/ali/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ali/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ali/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download([\n",
    "    \"names\",\n",
    "     \"stopwords\",\n",
    "     \"state_union\",\n",
    "     \"twitter_samples\",\n",
    "     \"movie_reviews\",\n",
    "     \"averaged_perceptron_tagger\",\n",
    "     \"vader_lexicon\",\n",
    "     \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will tell NLTK to find and download each resource based on its identifier.\n",
    "\n",
    "Should NLTK require additional resources that you haven’t installed, you’ll see a helpful LookupError with details and instructions to download the resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = nltk.corpus.shakespeare.word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LookupError specifies which resource is necessary for the requested operation along with instructions to download it using its identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'S',\n",
       " 'TRUMAN',\n",
       " 'S',\n",
       " 'ADDRESS',\n",
       " 'BEFORE',\n",
       " 'A',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'It',\n",
       " 'is',\n",
       " 'with',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'before',\n",
       " 'you',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'colleagues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Only',\n",
       " 'yesterday',\n",
       " 'we',\n",
       " 'laid',\n",
       " 'to',\n",
       " 'rest',\n",
       " 'the',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'our',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'At',\n",
       " 'a',\n",
       " 'time',\n",
       " 'like',\n",
       " 'this',\n",
       " 'words',\n",
       " 'are',\n",
       " 'inadequate',\n",
       " 'The',\n",
       " 'most',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'Yet',\n",
       " 'in',\n",
       " 'this',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'when',\n",
       " 'world',\n",
       " 'events',\n",
       " 'are',\n",
       " 'moving',\n",
       " 'so',\n",
       " 'rapidly',\n",
       " 'our',\n",
       " 'silence',\n",
       " 'might',\n",
       " 'be',\n",
       " 'misunderstood',\n",
       " 'and',\n",
       " 'might',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'to',\n",
       " 'our',\n",
       " 'enemies',\n",
       " 'In',\n",
       " 'His',\n",
       " 'infinite',\n",
       " 'wisdom',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'has',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'to',\n",
       " 'take',\n",
       " 'from',\n",
       " 'us',\n",
       " 'a',\n",
       " 'great',\n",
       " 'man',\n",
       " 'who',\n",
       " 'loved',\n",
       " 'and',\n",
       " 'was',\n",
       " 'beloved',\n",
       " 'by',\n",
       " 'all',\n",
       " 'humanity',\n",
       " 'No',\n",
       " 'man',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'fill',\n",
       " 'the',\n",
       " 'tremendous',\n",
       " 'void',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'passing',\n",
       " 'of',\n",
       " 'that',\n",
       " 'noble',\n",
       " 'soul',\n",
       " 'No',\n",
       " 'words',\n",
       " 'can',\n",
       " 'ease',\n",
       " 'the',\n",
       " 'aching',\n",
       " 'hearts',\n",
       " 'of',\n",
       " 'untold',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'every',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'and',\n",
       " 'color',\n",
       " 'The',\n",
       " 'world',\n",
       " 'knows',\n",
       " 'it',\n",
       " 'has',\n",
       " 'lost',\n",
       " 'a',\n",
       " 'heroic',\n",
       " 'champion',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'Tragic',\n",
       " 'fate',\n",
       " 'has',\n",
       " 'thrust',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'grave',\n",
       " 'responsibilities',\n",
       " 'We',\n",
       " 'must',\n",
       " 'carry',\n",
       " 'on',\n",
       " 'Our',\n",
       " 'departed',\n",
       " 'leader',\n",
       " 'never',\n",
       " 'looked',\n",
       " 'backward',\n",
       " 'He',\n",
       " 'looked',\n",
       " 'forward',\n",
       " 'and',\n",
       " 'moved',\n",
       " 'forward',\n",
       " 'That',\n",
       " 'is',\n",
       " 'what',\n",
       " 'he',\n",
       " 'would',\n",
       " 'want',\n",
       " 'us',\n",
       " 'to',\n",
       " 'do',\n",
       " 'That',\n",
       " 'is',\n",
       " 'what',\n",
       " 'America',\n",
       " 'will',\n",
       " 'do',\n",
       " 'So',\n",
       " 'much',\n",
       " 'blood',\n",
       " 'has',\n",
       " 'already',\n",
       " 'been',\n",
       " 'shed',\n",
       " 'for',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'we',\n",
       " 'cherish',\n",
       " 'and',\n",
       " 'for',\n",
       " 'which',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'lived',\n",
       " 'and',\n",
       " 'died',\n",
       " 'that',\n",
       " 'we',\n",
       " 'dare',\n",
       " 'not',\n",
       " 'permit',\n",
       " 'even',\n",
       " 'a',\n",
       " 'momentary',\n",
       " 'pause',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hard',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'victory',\n",
       " 'Today',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'to',\n",
       " 'America',\n",
       " 'for',\n",
       " 'enlightened',\n",
       " 'leadership',\n",
       " 'to',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'progress',\n",
       " 'Such',\n",
       " 'a',\n",
       " 'leadership',\n",
       " 'requires',\n",
       " 'vision',\n",
       " 'courage',\n",
       " 'and',\n",
       " 'tolerance',\n",
       " 'It',\n",
       " 'can',\n",
       " 'be',\n",
       " 'provided',\n",
       " 'only',\n",
       " 'by',\n",
       " 'a',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'deeply',\n",
       " 'devoted',\n",
       " 'to',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'ideals',\n",
       " 'With',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'I',\n",
       " 'call',\n",
       " 'upon',\n",
       " 'all',\n",
       " 'Americans',\n",
       " 'to',\n",
       " 'help',\n",
       " 'me',\n",
       " 'keep',\n",
       " 'our',\n",
       " 'nation',\n",
       " 'united',\n",
       " 'in',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'which',\n",
       " 'have',\n",
       " 'been',\n",
       " 'so',\n",
       " 'eloquently',\n",
       " 'proclaimed',\n",
       " 'by',\n",
       " 'Franklin',\n",
       " 'Roosevelt',\n",
       " 'I',\n",
       " 'want',\n",
       " 'in',\n",
       " 'turn',\n",
       " 'to',\n",
       " 'assure',\n",
       " 'my',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'those',\n",
       " 'who',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'liberty',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'world',\n",
       " 'that',\n",
       " 'I',\n",
       " 'will',\n",
       " 'support',\n",
       " 'and',\n",
       " 'defend',\n",
       " 'those',\n",
       " 'ideals',\n",
       " 'with',\n",
       " 'all',\n",
       " 'my',\n",
       " 'strength',\n",
       " 'and',\n",
       " 'all',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'That',\n",
       " 'is',\n",
       " 'my',\n",
       " 'duty',\n",
       " 'and',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'shirk',\n",
       " 'it',\n",
       " 'So',\n",
       " 'that',\n",
       " 'there',\n",
       " 'can',\n",
       " 'be',\n",
       " 'no',\n",
       " 'possible',\n",
       " 'misunderstanding',\n",
       " 'both',\n",
       " 'Germany',\n",
       " 'and',\n",
       " 'Japan',\n",
       " 'can',\n",
       " 'be',\n",
       " 'certain',\n",
       " 'beyond',\n",
       " 'any',\n",
       " 'shadow',\n",
       " 'of',\n",
       " 'a',\n",
       " 'doubt',\n",
       " 'that',\n",
       " 'America',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'the',\n",
       " 'fight',\n",
       " 'for',\n",
       " 'freedom',\n",
       " 'until',\n",
       " 'no',\n",
       " 'vestige',\n",
       " 'of',\n",
       " 'resistance',\n",
       " 'remains',\n",
       " 'We',\n",
       " 'are',\n",
       " 'deeply',\n",
       " 'conscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'much',\n",
       " 'hard',\n",
       " 'fighting',\n",
       " 'is',\n",
       " 'still',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'us',\n",
       " 'Having',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'such',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'to',\n",
       " 'make',\n",
       " 'complete',\n",
       " 'victory',\n",
       " 'certain',\n",
       " 'America',\n",
       " 'will',\n",
       " 'never',\n",
       " 'become',\n",
       " 'a',\n",
       " 'party',\n",
       " 'to',\n",
       " 'any',\n",
       " 'plan',\n",
       " 'for',\n",
       " 'partial',\n",
       " 'victory',\n",
       " 'To',\n",
       " 'settle',\n",
       " 'for',\n",
       " 'merely',\n",
       " 'another',\n",
       " 'temporary',\n",
       " 'respite',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'jeopardize',\n",
       " 'the',\n",
       " 'future',\n",
       " 'security',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Our',\n",
       " 'demand',\n",
       " 'has',\n",
       " 'been',\n",
       " 'and',\n",
       " 'it',\n",
       " 'remains',\n",
       " 'Unconditional',\n",
       " 'Surrender',\n",
       " 'We',\n",
       " 'will',\n",
       " 'not',\n",
       " 'traffic',\n",
       " 'with',\n",
       " 'the',\n",
       " 'breakers',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'on',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'The',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'making',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'very',\n",
       " 'grave',\n",
       " 'responsibility',\n",
       " 'must',\n",
       " 'rest',\n",
       " 'with',\n",
       " 'the',\n",
       " 'defenders',\n",
       " 'of',\n",
       " 'the',\n",
       " 'peace',\n",
       " 'We',\n",
       " 'are',\n",
       " 'not',\n",
       " 'unconscious',\n",
       " 'of',\n",
       " 'the',\n",
       " 'dictates',\n",
       " 'of',\n",
       " 'humanity',\n",
       " 'We',\n",
       " 'do',\n",
       " 'not',\n",
       " 'wish',\n",
       " 'to',\n",
       " 'see',\n",
       " 'unnecessary',\n",
       " 'or',\n",
       " 'unjustified',\n",
       " 'suffering',\n",
       " 'But',\n",
       " 'the',\n",
       " 'laws',\n",
       " 'of',\n",
       " 'Go',\n",
       " 'd',\n",
       " 'and',\n",
       " 'of',\n",
       " 'man',\n",
       " 'have',\n",
       " 'been',\n",
       " 'violated',\n",
       " 'and',\n",
       " 'the',\n",
       " 'guilty',\n",
       " 'must',\n",
       " 'not',\n",
       " 'go',\n",
       " 'unpunished',\n",
       " 'Nothing',\n",
       " 'shall',\n",
       " 'shake',\n",
       " 'our',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'punish',\n",
       " 'the',\n",
       " 'war',\n",
       " 'criminals',\n",
       " 'even',\n",
       " 'though',\n",
       " 'we',\n",
       " 'must',\n",
       " 'pursue',\n",
       " 'them',\n",
       " 'to',\n",
       " 'the',\n",
       " 'ends',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'Lasting',\n",
       " 'peace',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'secured',\n",
       " 'if',\n",
       " 'we',\n",
       " 'permit',\n",
       " 'our',\n",
       " 'dangerous',\n",
       " 'opponents',\n",
       " 'to',\n",
       " 'plot',\n",
       " 'future',\n",
       " 'wars',\n",
       " 'with',\n",
       " 'impunity',\n",
       " 'at',\n",
       " 'any',\n",
       " 'mountain',\n",
       " 'retreat',\n",
       " 'however',\n",
       " 'distant',\n",
       " 'In',\n",
       " 'this',\n",
       " 'shrinking',\n",
       " 'world',\n",
       " 'it',\n",
       " 'is',\n",
       " 'futile',\n",
       " 'to',\n",
       " 'seek',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'geographical',\n",
       " 'barriers',\n",
       " 'Real',\n",
       " 'security',\n",
       " 'will',\n",
       " 'be',\n",
       " 'found',\n",
       " 'only',\n",
       " 'in',\n",
       " 'law',\n",
       " 'and',\n",
       " 'in',\n",
       " 'justice',\n",
       " 'Here',\n",
       " 'in',\n",
       " 'America',\n",
       " 'we',\n",
       " 'have',\n",
       " 'labored',\n",
       " 'long',\n",
       " 'and',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'a',\n",
       " 'social',\n",
       " 'order',\n",
       " 'worthy',\n",
       " 'of',\n",
       " 'our',\n",
       " 'great',\n",
       " 'heritage',\n",
       " 'In',\n",
       " 'our',\n",
       " 'time',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'has',\n",
       " 'been',\n",
       " 'made',\n",
       " 'toward',\n",
       " 'a',\n",
       " 'really',\n",
       " 'democratic',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'Let',\n",
       " 'me',\n",
       " 'assure',\n",
       " 'the',\n",
       " 'forward',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'of',\n",
       " 'America',\n",
       " 'that',\n",
       " 'there',\n",
       " 'w',\n",
       " 'ill',\n",
       " 'be',\n",
       " 'no',\n",
       " 'relaxation',\n",
       " 'in',\n",
       " 'our',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'common',\n",
       " 'people',\n",
       " 'In',\n",
       " 'the',\n",
       " 'difficult',\n",
       " 'days',\n",
       " 'ahead',\n",
       " 'unquestionably',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'staggering',\n",
       " 'proportions',\n",
       " 'However',\n",
       " 'with',\n",
       " 'the',\n",
       " 'faith',\n",
       " 'of',\n",
       " 'our',\n",
       " 'fathers',\n",
       " 'in',\n",
       " 'our',\n",
       " 'hearts',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'fear',\n",
       " 'the',\n",
       " 'future',\n",
       " 'On',\n",
       " 'the',\n",
       " 'battlefields',\n",
       " 'we',\n",
       " 'have',\n",
       " 'frequently',\n",
       " 'faced',\n",
       " 'overwhelming',\n",
       " 'odds',\n",
       " 'and',\n",
       " 'won',\n",
       " 'At',\n",
       " 'home',\n",
       " 'Americans',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'less',\n",
       " 'resolute',\n",
       " 'We',\n",
       " 'shall',\n",
       " 'never',\n",
       " 'cease',\n",
       " 'our',\n",
       " 'struggle',\n",
       " 'to',\n",
       " 'preserve',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'our',\n",
       " 'American',\n",
       " 'way',\n",
       " 'of',\n",
       " 'life',\n",
       " 'At',\n",
       " 'this',\n",
       " 'moment',\n",
       " 'America',\n",
       " 'along',\n",
       " 'with',\n",
       " 'her',\n",
       " 'brave',\n",
       " 'Allies',\n",
       " 'is',\n",
       " 'paying',\n",
       " 'again',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'for',\n",
       " 'the',\n",
       " 'defense',\n",
       " 'of',\n",
       " 'our',\n",
       " 'freedom',\n",
       " 'With',\n",
       " 'characteristic',\n",
       " 'energy',\n",
       " 'we',\n",
       " 'are',\n",
       " 'assisting',\n",
       " 'in',\n",
       " 'the',\n",
       " 'liberation',\n",
       " 'of',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'Gradually',\n",
       " 'the',\n",
       " 'shackles',\n",
       " 'of',\n",
       " 'slavery',\n",
       " 'are',\n",
       " 'being',\n",
       " 'broken',\n",
       " 'by',\n",
       " 't',\n",
       " 'he',\n",
       " 'forces',\n",
       " 'of',\n",
       " 'freedom',\n",
       " 'All',\n",
       " 'of',\n",
       " 'us',\n",
       " 'are',\n",
       " 'praying',\n",
       " 'for',\n",
       " 'a',\n",
       " 'speedy',\n",
       " 'victory',\n",
       " 'Every',\n",
       " 'day',\n",
       " 'peace',\n",
       " 'is',\n",
       " 'delayed',\n",
       " 'costs',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'toll',\n",
       " 'The',\n",
       " 'armies',\n",
       " 'of',\n",
       " 'liberation',\n",
       " 'today',\n",
       " 'are',\n",
       " 'bringing',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'Hitler',\n",
       " 's',\n",
       " 'ghastly',\n",
       " 'threat',\n",
       " 'to',\n",
       " 'dominate',\n",
       " 'the',\n",
       " 'world',\n",
       " 'Tokyo',\n",
       " 'rocks',\n",
       " 'under',\n",
       " 'the',\n",
       " 'weight',\n",
       " 'of',\n",
       " 'our',\n",
       " 'bombs',\n",
       " 'The',\n",
       " 'grand',\n",
       " 'strategy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'determined',\n",
       " 'due',\n",
       " 'in',\n",
       " 'no',\n",
       " 'small',\n",
       " 'measure',\n",
       " 'to',\n",
       " 'the',\n",
       " 'vision',\n",
       " 'of',\n",
       " 'our',\n",
       " 'departed',\n",
       " 'Commander',\n",
       " 'in',\n",
       " 'Chief',\n",
       " 'We',\n",
       " 'are',\n",
       " 'now',\n",
       " 'carrying',\n",
       " 'out',\n",
       " 'our',\n",
       " 'part',\n",
       " 'of',\n",
       " 'that',\n",
       " 'strategy',\n",
       " 'under',\n",
       " 'the',\n",
       " 'able',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'Admiral',\n",
       " 'Leahy',\n",
       " 'General',\n",
       " 'Marshall',\n",
       " 'A',\n",
       " 'dmiral',\n",
       " 'King',\n",
       " 'General',\n",
       " 'Arnold',\n",
       " 'General',\n",
       " 'Eisenhower',\n",
       " 'Admiral',\n",
       " 'Nimitz',\n",
       " 'and',\n",
       " 'General',\n",
       " 'MacArthur',\n",
       " 'I',\n",
       " 'want',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'to',\n",
       " 'know',\n",
       " 'that',\n",
       " 'this',\n",
       " 'direction',\n",
       " 'must',\n",
       " 'and',\n",
       " 'will',\n",
       " 'remain',\n",
       " 'unchanged',\n",
       " 'and',\n",
       " 'unhampered',\n",
       " 'Our',\n",
       " 'debt',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heroic',\n",
       " 'men',\n",
       " 'and',\n",
       " 'valiant',\n",
       " 'women',\n",
       " 'in',\n",
       " 'the',\n",
       " 'service',\n",
       " 'of',\n",
       " 'our',\n",
       " 'country',\n",
       " 'can',\n",
       " 'never',\n",
       " 'be',\n",
       " 'repaid',\n",
       " 'They',\n",
       " 'have',\n",
       " 'earned',\n",
       " 'our',\n",
       " 'undying',\n",
       " 'gratitude',\n",
       " 'America',\n",
       " 'will',\n",
       " 'never',\n",
       " 'forget',\n",
       " 'their',\n",
       " 'sacrifices',\n",
       " 'Because',\n",
       " 'of',\n",
       " 'these',\n",
       " 'sacrifices',\n",
       " 'the',\n",
       " 'dawn',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'throughout',\n",
       " 'th',\n",
       " 'e',\n",
       " 'world',\n",
       " 'slowly',\n",
       " 'casts',\n",
       " 'its',\n",
       " 'gleam',\n",
       " 'across',\n",
       " 'the',\n",
       " 'horizon',\n",
       " 'Our',\n",
       " 'forefathers',\n",
       " 'came',\n",
       " 'to',\n",
       " 'our',\n",
       " 'rugged',\n",
       " 'shores',\n",
       " 'in',\n",
       " 'search',\n",
       " 'of',\n",
       " 'religious',\n",
       " 'tolerance',\n",
       " 'political',\n",
       " 'freedom',\n",
       " 'and',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'For',\n",
       " 'those',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'they',\n",
       " 'risked',\n",
       " 'their',\n",
       " 'lives',\n",
       " 'We',\n",
       " 'well',\n",
       " 'know',\n",
       " 'today',\n",
       " 'that',\n",
       " 'such',\n",
       " 'rights',\n",
       " 'can',\n",
       " 'be',\n",
       " 'preserved',\n",
       " 'only',\n",
       " 'by',\n",
       " 'constant',\n",
       " 'vigilance',\n",
       " 'the',\n",
       " 'eternal',\n",
       " 'price',\n",
       " 'of',\n",
       " 'liberty',\n",
       " 'Within',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'after',\n",
       " 'I',\n",
       " 'took',\n",
       " 'the',\n",
       " 'oath',\n",
       " 'of',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides a small corpus of stop words that you can load into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can remove stop words from your original word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'TRUMAN',\n",
       " 'ADDRESS',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friends',\n",
       " 'colleagues',\n",
       " 'Congress',\n",
       " 'United',\n",
       " 'States',\n",
       " 'yesterday',\n",
       " 'laid',\n",
       " 'rest',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'time',\n",
       " 'like',\n",
       " 'words',\n",
       " 'inadequate',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'Yet',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'world',\n",
       " 'events',\n",
       " 'moving',\n",
       " 'rapidly',\n",
       " 'silence',\n",
       " 'might',\n",
       " 'misunderstood',\n",
       " 'might',\n",
       " 'give',\n",
       " 'comfort',\n",
       " 'enemies',\n",
       " 'infinite',\n",
       " 'wisdom',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'seen',\n",
       " 'fit',\n",
       " 'take',\n",
       " 'us',\n",
       " 'great',\n",
       " 'man',\n",
       " 'loved',\n",
       " 'beloved',\n",
       " 'humanity',\n",
       " 'man',\n",
       " 'could',\n",
       " 'possibly',\n",
       " 'fill',\n",
       " 'tremendous',\n",
       " 'void',\n",
       " 'left',\n",
       " 'passing',\n",
       " 'noble',\n",
       " 'soul',\n",
       " 'words',\n",
       " 'ease',\n",
       " 'aching',\n",
       " 'hearts',\n",
       " 'untold',\n",
       " 'millions',\n",
       " 'every',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'color',\n",
       " 'world',\n",
       " 'knows',\n",
       " 'lost',\n",
       " 'heroic',\n",
       " 'champion',\n",
       " 'justice',\n",
       " 'freedom',\n",
       " 'Tragic',\n",
       " 'fate',\n",
       " 'thrust',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'grave',\n",
       " 'responsibilities',\n",
       " 'must',\n",
       " 'carry',\n",
       " 'departed',\n",
       " 'leader',\n",
       " 'never',\n",
       " 'looked',\n",
       " 'backward',\n",
       " 'looked',\n",
       " 'forward',\n",
       " 'moved',\n",
       " 'forward',\n",
       " 'would',\n",
       " 'want',\n",
       " 'us',\n",
       " 'America',\n",
       " 'much',\n",
       " 'blood',\n",
       " 'already',\n",
       " 'shed',\n",
       " 'ideals',\n",
       " 'cherish',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'lived',\n",
       " 'died',\n",
       " 'dare',\n",
       " 'permit',\n",
       " 'even',\n",
       " 'momentary',\n",
       " 'pause',\n",
       " 'hard',\n",
       " 'fight',\n",
       " 'victory',\n",
       " 'Today',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'looking',\n",
       " 'America',\n",
       " 'enlightened',\n",
       " 'leadership',\n",
       " 'peace',\n",
       " 'progress',\n",
       " 'leadership',\n",
       " 'requires',\n",
       " 'vision',\n",
       " 'courage',\n",
       " 'tolerance',\n",
       " 'provided',\n",
       " 'united',\n",
       " 'nation',\n",
       " 'deeply',\n",
       " 'devoted',\n",
       " 'highest',\n",
       " 'ideals',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'call',\n",
       " 'upon',\n",
       " 'Americans',\n",
       " 'help',\n",
       " 'keep',\n",
       " 'nation',\n",
       " 'united',\n",
       " 'defense',\n",
       " 'ideals',\n",
       " 'eloquently',\n",
       " 'proclaimed',\n",
       " 'Franklin',\n",
       " 'Roosevelt',\n",
       " 'want',\n",
       " 'turn',\n",
       " 'assure',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " 'love',\n",
       " 'peace',\n",
       " 'liberty',\n",
       " 'throughout',\n",
       " 'world',\n",
       " 'support',\n",
       " 'defend',\n",
       " 'ideals',\n",
       " 'strength',\n",
       " 'heart',\n",
       " 'duty',\n",
       " 'shall',\n",
       " 'shirk',\n",
       " 'possible',\n",
       " 'misunderstanding',\n",
       " 'Germany',\n",
       " 'Japan',\n",
       " 'certain',\n",
       " 'beyond',\n",
       " 'shadow',\n",
       " 'doubt',\n",
       " 'America',\n",
       " 'continue',\n",
       " 'fight',\n",
       " 'freedom',\n",
       " 'vestige',\n",
       " 'resistance',\n",
       " 'remains',\n",
       " 'deeply',\n",
       " 'conscious',\n",
       " 'fact',\n",
       " 'much',\n",
       " 'hard',\n",
       " 'fighting',\n",
       " 'still',\n",
       " 'ahead',\n",
       " 'us',\n",
       " 'pay',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'make',\n",
       " 'complete',\n",
       " 'victory',\n",
       " 'certain',\n",
       " 'America',\n",
       " 'never',\n",
       " 'become',\n",
       " 'party',\n",
       " 'plan',\n",
       " 'partial',\n",
       " 'victory',\n",
       " 'settle',\n",
       " 'merely',\n",
       " 'another',\n",
       " 'temporary',\n",
       " 'respite',\n",
       " 'would',\n",
       " 'surely',\n",
       " 'jeopardize',\n",
       " 'future',\n",
       " 'security',\n",
       " 'world',\n",
       " 'demand',\n",
       " 'remains',\n",
       " 'Unconditional',\n",
       " 'Surrender',\n",
       " 'traffic',\n",
       " 'breakers',\n",
       " 'peace',\n",
       " 'terms',\n",
       " 'peace',\n",
       " 'responsibility',\n",
       " 'making',\n",
       " 'peace',\n",
       " 'grave',\n",
       " 'responsibility',\n",
       " 'must',\n",
       " 'rest',\n",
       " 'defenders',\n",
       " 'peace',\n",
       " 'unconscious',\n",
       " 'dictates',\n",
       " 'humanity',\n",
       " 'wish',\n",
       " 'see',\n",
       " 'unnecessary',\n",
       " 'unjustified',\n",
       " 'suffering',\n",
       " 'laws',\n",
       " 'Go',\n",
       " 'man',\n",
       " 'violated',\n",
       " 'guilty',\n",
       " 'must',\n",
       " 'go',\n",
       " 'unpunished',\n",
       " 'Nothing',\n",
       " 'shall',\n",
       " 'shake',\n",
       " 'determination',\n",
       " 'punish',\n",
       " 'war',\n",
       " 'criminals',\n",
       " 'even',\n",
       " 'though',\n",
       " 'must',\n",
       " 'pursue',\n",
       " 'ends',\n",
       " 'earth',\n",
       " 'Lasting',\n",
       " 'peace',\n",
       " 'never',\n",
       " 'secured',\n",
       " 'permit',\n",
       " 'dangerous',\n",
       " 'opponents',\n",
       " 'plot',\n",
       " 'future',\n",
       " 'wars',\n",
       " 'impunity',\n",
       " 'mountain',\n",
       " 'retreat',\n",
       " 'however',\n",
       " 'distant',\n",
       " 'shrinking',\n",
       " 'world',\n",
       " 'futile',\n",
       " 'seek',\n",
       " 'safety',\n",
       " 'behind',\n",
       " 'geographical',\n",
       " 'barriers',\n",
       " 'Real',\n",
       " 'security',\n",
       " 'found',\n",
       " 'law',\n",
       " 'justice',\n",
       " 'America',\n",
       " 'labored',\n",
       " 'long',\n",
       " 'hard',\n",
       " 'achieve',\n",
       " 'social',\n",
       " 'order',\n",
       " 'worthy',\n",
       " 'great',\n",
       " 'heritage',\n",
       " 'time',\n",
       " 'tremendous',\n",
       " 'progress',\n",
       " 'made',\n",
       " 'toward',\n",
       " 'really',\n",
       " 'democratic',\n",
       " 'way',\n",
       " 'life',\n",
       " 'Let',\n",
       " 'assure',\n",
       " 'forward',\n",
       " 'looking',\n",
       " 'people',\n",
       " 'America',\n",
       " 'w',\n",
       " 'ill',\n",
       " 'relaxation',\n",
       " 'efforts',\n",
       " 'improve',\n",
       " 'lot',\n",
       " 'common',\n",
       " 'people',\n",
       " 'difficult',\n",
       " 'days',\n",
       " 'ahead',\n",
       " 'unquestionably',\n",
       " 'shall',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'staggering',\n",
       " 'proportions',\n",
       " 'However',\n",
       " 'faith',\n",
       " 'fathers',\n",
       " 'hearts',\n",
       " 'fear',\n",
       " 'future',\n",
       " 'battlefields',\n",
       " 'frequently',\n",
       " 'faced',\n",
       " 'overwhelming',\n",
       " 'odds',\n",
       " 'home',\n",
       " 'Americans',\n",
       " 'less',\n",
       " 'resolute',\n",
       " 'shall',\n",
       " 'never',\n",
       " 'cease',\n",
       " 'struggle',\n",
       " 'preserve',\n",
       " 'maintain',\n",
       " 'American',\n",
       " 'way',\n",
       " 'life',\n",
       " 'moment',\n",
       " 'America',\n",
       " 'along',\n",
       " 'brave',\n",
       " 'Allies',\n",
       " 'paying',\n",
       " 'heavy',\n",
       " 'price',\n",
       " 'defense',\n",
       " 'freedom',\n",
       " 'characteristic',\n",
       " 'energy',\n",
       " 'assisting',\n",
       " 'liberation',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'Gradually',\n",
       " 'shackles',\n",
       " 'slavery',\n",
       " 'broken',\n",
       " 'forces',\n",
       " 'freedom',\n",
       " 'us',\n",
       " 'praying',\n",
       " 'speedy',\n",
       " 'victory',\n",
       " 'Every',\n",
       " 'day',\n",
       " 'peace',\n",
       " 'delayed',\n",
       " 'costs',\n",
       " 'terrible',\n",
       " 'toll',\n",
       " 'armies',\n",
       " 'liberation',\n",
       " 'today',\n",
       " 'bringing',\n",
       " 'end',\n",
       " 'Hitler',\n",
       " 'ghastly',\n",
       " 'threat',\n",
       " 'dominate',\n",
       " 'world',\n",
       " 'Tokyo',\n",
       " 'rocks',\n",
       " 'weight',\n",
       " 'bombs',\n",
       " 'grand',\n",
       " 'strategy',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'war',\n",
       " 'determined',\n",
       " 'due',\n",
       " 'small',\n",
       " 'measure',\n",
       " 'vision',\n",
       " 'departed',\n",
       " 'Commander',\n",
       " 'Chief',\n",
       " 'carrying',\n",
       " 'part',\n",
       " 'strategy',\n",
       " 'able',\n",
       " 'direction',\n",
       " 'Admiral',\n",
       " 'Leahy',\n",
       " 'General',\n",
       " 'Marshall',\n",
       " 'dmiral',\n",
       " 'King',\n",
       " 'General',\n",
       " 'Arnold',\n",
       " 'General',\n",
       " 'Eisenhower',\n",
       " 'Admiral',\n",
       " 'Nimitz',\n",
       " 'General',\n",
       " 'MacArthur',\n",
       " 'want',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'know',\n",
       " 'direction',\n",
       " 'must',\n",
       " 'remain',\n",
       " 'unchanged',\n",
       " 'unhampered',\n",
       " 'debt',\n",
       " 'heroic',\n",
       " 'men',\n",
       " 'valiant',\n",
       " 'women',\n",
       " 'service',\n",
       " 'country',\n",
       " 'never',\n",
       " 'repaid',\n",
       " 'earned',\n",
       " 'undying',\n",
       " 'gratitude',\n",
       " 'America',\n",
       " 'never',\n",
       " 'forget',\n",
       " 'sacrifices',\n",
       " 'sacrifices',\n",
       " 'dawn',\n",
       " 'justice',\n",
       " 'freedom',\n",
       " 'throughout',\n",
       " 'th',\n",
       " 'e',\n",
       " 'world',\n",
       " 'slowly',\n",
       " 'casts',\n",
       " 'gleam',\n",
       " 'across',\n",
       " 'horizon',\n",
       " 'forefathers',\n",
       " 'came',\n",
       " 'rugged',\n",
       " 'shores',\n",
       " 'search',\n",
       " 'religious',\n",
       " 'tolerance',\n",
       " 'political',\n",
       " 'freedom',\n",
       " 'economic',\n",
       " 'opportunity',\n",
       " 'fundamental',\n",
       " 'rights',\n",
       " 'risked',\n",
       " 'lives',\n",
       " 'well',\n",
       " 'know',\n",
       " 'today',\n",
       " 'rights',\n",
       " 'preserved',\n",
       " 'constant',\n",
       " 'vigilance',\n",
       " 'eternal',\n",
       " 'price',\n",
       " 'liberty',\n",
       " 'Within',\n",
       " 'hour',\n",
       " 'took',\n",
       " 'oath',\n",
       " 'office',\n",
       " 'announced',\n",
       " 'San',\n",
       " 'Francisco',\n",
       " 'Conference',\n",
       " 'would',\n",
       " 'proceed',\n",
       " 'face',\n",
       " 'problems',\n",
       " 'peace',\n",
       " 'courage',\n",
       " 'faced',\n",
       " 'mastered',\n",
       " 'problems',\n",
       " 'war',\n",
       " 'memory',\n",
       " 'made',\n",
       " 'supreme',\n",
       " 'sacrifice',\n",
       " 'memory',\n",
       " 'fallen',\n",
       " 'President',\n",
       " 'shall',\n",
       " 'fail',\n",
       " 'enough',\n",
       " 'yearn',\n",
       " 'peace',\n",
       " 'must',\n",
       " 'work',\n",
       " 'necessary',\n",
       " 'fight',\n",
       " 'task',\n",
       " 'creating',\n",
       " 'sound',\n",
       " 'international',\n",
       " 'organization',\n",
       " 'complicated',\n",
       " 'difficult',\n",
       " 'Yet',\n",
       " 'without',\n",
       " 'organization',\n",
       " 'rights',\n",
       " 'man',\n",
       " 'earth',\n",
       " 'cannot',\n",
       " 'protected',\n",
       " 'Machi',\n",
       " 'nery',\n",
       " 'settlement',\n",
       " 'international',\n",
       " 'differences',\n",
       " 'must',\n",
       " 'found',\n",
       " 'Without',\n",
       " 'machinery',\n",
       " 'entire',\n",
       " 'world',\n",
       " 'remain',\n",
       " 'armed',\n",
       " 'camp',\n",
       " 'world',\n",
       " 'doomed',\n",
       " 'deadly',\n",
       " 'conflict',\n",
       " 'devoid',\n",
       " 'hope',\n",
       " 'real',\n",
       " 'peace',\n",
       " 'Fortunately',\n",
       " 'people',\n",
       " 'retained',\n",
       " 'hope',\n",
       " 'durable',\n",
       " 'peace',\n",
       " 'Thoughtful',\n",
       " 'people',\n",
       " 'always',\n",
       " 'faith',\n",
       " 'ultimately',\n",
       " 'justice',\n",
       " 'must',\n",
       " 'triumph',\n",
       " 'Past',\n",
       " 'experience',\n",
       " 'surely',\n",
       " 'indicates',\n",
       " 'without',\n",
       " 'justice',\n",
       " 'enduring',\n",
       " 'peace',\n",
       " 'becomes',\n",
       " 'impossible',\n",
       " 'bitter',\n",
       " 'despair',\n",
       " 'people',\n",
       " 'come',\n",
       " 'believe',\n",
       " 'wars',\n",
       " 'inevitable',\n",
       " 'tragic',\n",
       " 'fatalism',\n",
       " 'insist',\n",
       " 'wars',\n",
       " 'always',\n",
       " 'necessity',\n",
       " 'necessity',\n",
       " 'wars',\n",
       " 'always',\n",
       " 'defeatism',\n",
       " 'men',\n",
       " 'women',\n",
       " 'good',\n",
       " 'must',\n",
       " 'yield',\n",
       " 'outlook',\n",
       " 'humanity',\n",
       " 'hopeless',\n",
       " 'dark',\n",
       " 'hours',\n",
       " 'horrible',\n",
       " 'war',\n",
       " 'entire',\n",
       " 'nations',\n",
       " 'kept',\n",
       " 'going',\n",
       " 'something',\n",
       " 'intangible',\n",
       " 'hope',\n",
       " 'warned',\n",
       " 'abject',\n",
       " 'submission',\n",
       " 'offered',\n",
       " 'salvation',\n",
       " 'overwhelming',\n",
       " 'power',\n",
       " 'hope',\n",
       " 'showed',\n",
       " 'way',\n",
       " 'victory',\n",
       " 'Hope',\n",
       " 'become',\n",
       " 'secret',\n",
       " 'weapon',\n",
       " 'forces',\n",
       " 'liberation',\n",
       " 'Aggressors',\n",
       " 'could',\n",
       " 'dominate',\n",
       " 'human',\n",
       " 'mind',\n",
       " 'long',\n",
       " 'hope',\n",
       " 'remains',\n",
       " 'spirit',\n",
       " 'man',\n",
       " 'never',\n",
       " 'crushed',\n",
       " 'hope',\n",
       " 'alone',\n",
       " 'sufficient',\n",
       " 'avert',\n",
       " 'war',\n",
       " 'must',\n",
       " 'hope',\n",
       " 'must',\n",
       " 'faith',\n",
       " 'enough',\n",
       " 'work',\n",
       " 'peace',\n",
       " 'loving',\n",
       " 'nations',\n",
       " 'maintain',\n",
       " 'peace',\n",
       " 'Hope',\n",
       " 'enough',\n",
       " 'beat',\n",
       " 'back',\n",
       " 'aggressors',\n",
       " 'long',\n",
       " 'peace',\n",
       " 'loving',\n",
       " 'nations',\n",
       " 'unwilling',\n",
       " 'come',\n",
       " 'defense',\n",
       " 'aggressors',\n",
       " 'beaten',\n",
       " 'back',\n",
       " 'peace',\n",
       " 'loving',\n",
       " 'nations',\n",
       " 'united',\n",
       " 'defend',\n",
       " 'wars',\n",
       " 'future',\n",
       " 'prevented',\n",
       " 'nations',\n",
       " 'must',\n",
       " 'united',\n",
       " 'determination',\n",
       " 'keep',\n",
       " 'peace',\n",
       " 'law',\n",
       " 'Nothing',\n",
       " 'essential',\n",
       " 'future',\n",
       " 'peace',\n",
       " 'world',\n",
       " 'continued',\n",
       " 'cooperation',\n",
       " 'nations',\n",
       " 'muster',\n",
       " 'force',\n",
       " 'necessary',\n",
       " 'defeat',\n",
       " 'conspiracy',\n",
       " 'Axis',\n",
       " 'powers',\n",
       " 'dominate',\n",
       " 'world',\n",
       " 'great',\n",
       " 'states',\n",
       " 'special',\n",
       " 'responsibility',\n",
       " 'enforce',\n",
       " 'peace',\n",
       " 'responsibility',\n",
       " 'based',\n",
       " 'upon',\n",
       " 'obligations',\n",
       " 'resting',\n",
       " 'upon',\n",
       " 'states',\n",
       " 'large',\n",
       " 'small',\n",
       " 'use',\n",
       " 'force',\n",
       " 'international',\n",
       " 'relations',\n",
       " 'except',\n",
       " 'defense',\n",
       " 'law',\n",
       " 'respon',\n",
       " 'sibility',\n",
       " 'great',\n",
       " 'states',\n",
       " 'serve',\n",
       " 'dominate',\n",
       " 'world',\n",
       " 'build',\n",
       " 'foundation',\n",
       " 'enduring',\n",
       " 'peace',\n",
       " 'must',\n",
       " 'work',\n",
       " 'harmony',\n",
       " 'friends',\n",
       " 'abroad',\n",
       " 'must',\n",
       " 'united',\n",
       " 'support',\n",
       " 'people',\n",
       " 'Even',\n",
       " 'experienced',\n",
       " 'pilot',\n",
       " 'cannot',\n",
       " 'bring',\n",
       " 'ship',\n",
       " 'safely',\n",
       " 'harbor',\n",
       " 'unless',\n",
       " 'full',\n",
       " 'cooperation',\n",
       " 'crew',\n",
       " 'benefit',\n",
       " 'every',\n",
       " 'individual',\n",
       " 'must',\n",
       " 'duty',\n",
       " 'appeal',\n",
       " 'every',\n",
       " 'American',\n",
       " 'regardless',\n",
       " 'party',\n",
       " 'race',\n",
       " 'creed',\n",
       " 'color',\n",
       " 'support',\n",
       " 'efforts',\n",
       " 'build',\n",
       " 'strong',\n",
       " 'lasting',\n",
       " 'United',\n",
       " 'Nations',\n",
       " 'Organization',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'surely',\n",
       " 'know',\n",
       " 'feel',\n",
       " 'help',\n",
       " 'hope',\n",
       " 'complete',\n",
       " 'one',\n",
       " 'greatest',\n",
       " 'tasks',\n",
       " 'ever',\n",
       " 'assigned',\n",
       " 'public',\n",
       " 'servant',\n",
       " 'Divine',\n",
       " 'guidance',\n",
       " 'help',\n",
       " 'find',\n",
       " 'new',\n",
       " 'passage',\n",
       " 'far',\n",
       " 'better',\n",
       " 'world',\n",
       " 'kindly',\n",
       " 'friendly',\n",
       " 'world',\n",
       " 'lasting',\n",
       " 'peace',\n",
       " 'confidence',\n",
       " 'depending',\n",
       " 'upon',\n",
       " 'destroy',\n",
       " 'greedy',\n",
       " 'tyrants',\n",
       " 'dreams',\n",
       " 'world',\n",
       " 'domination',\n",
       " 'cannot',\n",
       " 'continue',\n",
       " 'successive',\n",
       " 'generations',\n",
       " 'sacrifice',\n",
       " 'finest',\n",
       " 'youth',\n",
       " 'name',\n",
       " 'human',\n",
       " 'decency',\n",
       " 'civilization',\n",
       " 'rational',\n",
       " 'method',\n",
       " 'deciding',\n",
       " 'national',\n",
       " 'differences',\n",
       " 'must',\n",
       " 'found',\n",
       " 'America',\n",
       " 'must',\n",
       " 'assist',\n",
       " 'suffering',\n",
       " 'humanity',\n",
       " 'back',\n",
       " 'along',\n",
       " 'path',\n",
       " 'peaceful',\n",
       " 'progress',\n",
       " 'require',\n",
       " 'time',\n",
       " 'tolerance',\n",
       " 'shall',\n",
       " 'need',\n",
       " 'also',\n",
       " 'abiding',\n",
       " 'faith',\n",
       " 'people',\n",
       " 'kind',\n",
       " 'faith',\n",
       " 'courage',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'always',\n",
       " 'Today',\n",
       " 'America',\n",
       " 'become',\n",
       " 'one',\n",
       " 'powerful',\n",
       " 'forces',\n",
       " 'good',\n",
       " 'earth',\n",
       " 'must',\n",
       " 'keep',\n",
       " 'achieved',\n",
       " 'world',\n",
       " 'leadership',\n",
       " 'depend',\n",
       " 'solely',\n",
       " 'upon',\n",
       " 'military',\n",
       " 'naval',\n",
       " 'might',\n",
       " 'learned',\n",
       " 'fight',\n",
       " 'nations',\n",
       " 'common',\n",
       " 'defense',\n",
       " 'freedom',\n",
       " 'must',\n",
       " 'learn',\n",
       " 'live',\n",
       " 'nations',\n",
       " 'mutual',\n",
       " 'good',\n",
       " 'must',\n",
       " 'learn',\n",
       " 'trade',\n",
       " 'nations',\n",
       " 'may',\n",
       " 'mutual',\n",
       " 'advantage',\n",
       " 'increased',\n",
       " 'product',\n",
       " 'ion',\n",
       " 'increased',\n",
       " 'employment',\n",
       " 'better',\n",
       " 'standards',\n",
       " 'living',\n",
       " 'throughout',\n",
       " 'world',\n",
       " 'May',\n",
       " 'Americans',\n",
       " 'live',\n",
       " 'glorious',\n",
       " 'heritage',\n",
       " 'way',\n",
       " 'America',\n",
       " 'may',\n",
       " 'well',\n",
       " 'lead',\n",
       " 'world',\n",
       " 'peace',\n",
       " 'prosperity',\n",
       " 'moment',\n",
       " 'heart',\n",
       " 'prayer',\n",
       " 'assumed',\n",
       " 'heavy',\n",
       " 'duties',\n",
       " 'humbly',\n",
       " 'pray',\n",
       " 'Almighty',\n",
       " 'God',\n",
       " 'words',\n",
       " 'King',\n",
       " 'Solomon',\n",
       " 'Give',\n",
       " 'therefore',\n",
       " 'thy',\n",
       " 'servant',\n",
       " 'understanding',\n",
       " 'heart',\n",
       " 'judge',\n",
       " 'thy',\n",
       " 'people',\n",
       " 'may',\n",
       " 'discern',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'able',\n",
       " 'judge',\n",
       " 'thy',\n",
       " 'great',\n",
       " 'people',\n",
       " 'ask',\n",
       " 'good',\n",
       " 'faithful',\n",
       " 'servant',\n",
       " 'Lord',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [w for w in words if w.lower() not in stopwords]\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is how `word_tokenize()` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For', 'some', 'quick', 'analysis', ',', 'creating', 'a', 'corpus', 'could',\n",
      " 'be', 'overkill', '.', 'If', 'all', 'you', 'need', 'is', 'a', 'word', 'list',\n",
      " ',', 'there', 'are', 'simpler', 'ways', 'to', 'achieve', 'that', 'goal', '.']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "text = \"\"\"\n",
    " For some quick analysis, creating a corpus could be overkill.\n",
    " If all you need is a word list,\n",
    " there are simpler ways to achieve that goal.\"\"\"\n",
    "pprint(nltk.word_tokenize(text), width=79, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Frequency Distributions\n",
    "\n",
    "To build a frequency distribution with NLTK, construct the nltk.FreqDist class with a word list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(nltk.corpus.state_union.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'must': 1568, 'people': 1291, 'world': 1128, 'year': 1097, 'America': 1076, 'us': 1049, 'new': 1049, 'Congress': 1014, 'years': 827, 'American': 784, ...})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words: list[str] = nltk.word_tokenize(text)\n",
    "words = [w for w in text if w.lower() not in stopwords]\n",
    "words = [w for w in words if w.isalpha()]\n",
    "fd = nltk.FreqDist(words)\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the object, you can use methods like `.most_common()` and `.tabulate()` to start visualizing information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('must', 1568), ('people', 1291), ('world', 1128)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  must people  world \n",
      "  1568   1291   1128 \n"
     ]
    }
   ],
   "source": [
    "fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1076"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"america\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd[\"AMERICA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try creating a new frequency distribution that’s based on the initial one but normalizes all words to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'world': 3, 'year': 3, 'new': 3, 'congress': 3, 'peace': 3, 'federal': 3, 'program': 3, 'government': 3, 'war': 3, 'economic': 3, ...})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_fd = nltk.FreqDist([w.lower() for w in fd])\n",
    "lower_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world  year   new \n",
      "    3     3     3 \n"
     ]
    }
   ],
   "source": [
    "lower_fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Concordance and Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(nltk.corpus.state_union.words())\n",
    "text.concordance(\"america\", lines=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n"
     ]
    }
   ],
   "source": [
    "concordance_list = text.concordance_list(\"america\", lines=2)\n",
    "for entry in concordance_list:\n",
    "     print(entry.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    is better   than \n",
      "     3      3      3 \n"
     ]
    }
   ],
   "source": [
    "words: list[str] = nltk.word_tokenize(\n",
    "     \"\"\"Beautiful is better than ugly.\n",
    "     Explicit is better than implicit.\n",
    "     Simple is better than complex.\"\"\"\n",
    ")\n",
    "text = nltk.Text(words)\n",
    "fd = text.vocab()  # Equivalent to fd = nltk.FreqDist(words)\n",
    "fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'United', 'States'), 294), (('the', 'American', 'people'), 185)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.ngram_fd.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ('the', 'United', 'States') ('the', 'American', 'people') \n",
      "                          294                           185 \n"
     ]
    }
   ],
   "source": [
    "finder.ngram_fd.tabulate(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLTK’s Pre-Trained Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll get back a dictionary of different scores. The negative, neutral, and positive scores are related: They all add up to 1 and can’t be negative. The compound score is calculated differently. It’s not just an average, and it can range from -1 to 1.\n",
    "\n",
    "Now you’ll put it to the test against real data using two different corpora. First, load the twitter_samples corpus into a list of strings, making a replacement to render URLs inactive to avoid accidental clicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False RT @HouseOfTraitors: Why is @jo_coburn trying to argue with FARAGE on every question ?\n",
      "\n",
      "I didn't see Dimbelby do that to Camoron, Clegg, Mi…\n",
      "> False RT @LordAshcroft: Panelbase poll LAB 34% CON 32% UKIP 17% LDEM 8% GRNS 4%\n",
      "> True RT @BBCPropaganda: Even Nick Robinson struggling to spin it as a Miliband win. Cameron must have won by a mile. #BBCNews\n",
      "> True RT @earthygirl01: #bbbqt What a strong and commanding performance from Ed Miliband tonight Not like #ChickenDave @CCHQPress #HellYesEd http…\n",
      "> True Especially for three of you, LASS :) w/ Aling http//t.co/aRwmTLsFZr\n",
      "> False RT @Le_Figaro: David Cameron domine le dernier débat de la campagne électorale britannique http//t.co/9KXtl3ekWB\n",
      "> True RT @edballsmp: Tonight confirmed it: David Cameron and the Tories will cut child benefit if they win next week #bbcqt http//t.co/IHePV7fFLJ\n",
      "> False @SynergyFlying No!!! Why did you delete me?:(\n",
      "> False @paul7day She can bloody stay in Scotland Fuck Labour and Milliband  the lying bastard\n",
      "> True Nigel Farage really wants to leave the EU gravy train he feeds off. What a joker. #AskNigelFarage\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "negative_review_ids = nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "all_review_ids = positive_review_ids + negative_review_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def is_positive(review_id: str) -> bool:\n",
    "    \"\"\"True if the average of all sentence compound scores is positive.\"\"\"\n",
    "    text = nltk.corpus.movie_reviews.raw(review_id)\n",
    "    scores = [\n",
    "        sia.polarity_scores(sentence)[\"compound\"]\n",
    "        for sentence in nltk.sent_tokenize(text)\n",
    "    ]\n",
    "    return mean(scores) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.00% correct\n"
     ]
    }
   ],
   "source": [
    "shuffle(all_review_ids)\n",
    "correct = 0\n",
    "for review_id in all_review_ids:\n",
    "     if is_positive(review_id):\n",
    "         if review_id in positive_review_ids:\n",
    "             correct += 1\n",
    "     else:\n",
    "         if review_id in negative_review_ids:\n",
    "             correct += 1\n",
    "\n",
    "print(F\"{correct / len(all_review_ids):.2%} correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing NLTK's Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Useful Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words('english')\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"pos\"]))\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(nltk.corpus.movie_reviews.words(categories=[\"neg\"]))\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you’re ready to create the frequency distributions for your custom feature. Since many words are present in both positive and negative sets, begin by finding the common set so you can remove it from the distribution objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(postive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del postive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in postive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "\n",
    "positive_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"pos\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])\n",
    "negative_bigram_finder = nltk.collocations.BigramCollocationFinder.from_words([\n",
    "    w for w in nltk.corpus.movie_reviews.words(categories=[\"neg\"])\n",
    "    if w.isalpha() and w not in unwanted\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Using a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = dict()\n",
    "    wordcount = 0\n",
    "    compound_scores = list()\n",
    "    positive_scores = list()\n",
    "\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sentence):\n",
    "            if word.lower() in top_100_positive:\n",
    "                wordcount += 1\n",
    "        compound_scores.append(sia.polarity_scores(sentence)[\"compound\"])\n",
    "        positive_scores.append(sia.polarity_scores(sentence)[\"pos\"])\n",
    "    \n",
    "    # Adding 1 to the final compound score to always have positive numbers\n",
    "    # since some classfiers you'll use later don't work with negative numbers\n",
    "    features[\"mean_compound\"] = mean(compound_scores) + 1\n",
    "    features[\"mean_positive\"] = mean(positive_scores)\n",
    "    features[\"wordcount\"]     = wordcount\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train and evaluate a classifier, you’ll need to build a list of features for each text you’ll analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)),\"pos\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"pos\"])\n",
    "]\n",
    "features.extend([\n",
    "    (extract_features(nltk.corpus.movie_reviews.raw(review)), \"neg\")\n",
    "    for review in nltk.corpus.movie_reviews.fileids(categories=[\"neg\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               wordcount = 2                 pos : neg    =      4.9 : 1.0\n",
      "               wordcount = 0                 neg : pos    =      1.7 : 1.0\n",
      "               wordcount = 1                 pos : neg    =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 1/4 of the set for training\n",
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "classifier = nltk.NaiveBayesClassifier.train(features[:train_count])\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, features[train_count:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Additional Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import (\n",
    "    BernoulliNB,\n",
    "    ComplementNB,\n",
    "    MultinomialNB,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"BernoulliNB\": BernoulliNB(),\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "    \"MultinomialNB\": MultinomialNB(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=1000),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7fc180660400>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ali/miniconda3/envs/ali-gpu/lib/python3.11/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/ali/miniconda3/envs/ali-gpu/lib/python3.11/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ali/miniconda3/envs/ali-gpu/lib/python3.11/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ali/miniconda3/envs/ali-gpu/lib/python3.11/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.67% - BernoulliNB\n",
      "66.93% - ComplementNB\n",
      "67.20% - MultinomialNB\n",
      "70.47% - KNeighborsClassifier\n",
      "63.07% - DecisionTreeClassifier\n",
      "69.53% - RandomForestClassifier\n",
      "73.60% - LogisticRegression\n",
      "74.00% - MLPClassifier\n",
      "69.67% - AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "# Use 1/4 of the set for training\n",
    "train_count = len(features) // 4\n",
    "shuffle(features)\n",
    "for name, sklearn_classifier in classifiers.items():\n",
    "     classifier = nltk.classify.SklearnClassifier(sklearn_classifier)\n",
    "     classifier.train(features[:train_count])\n",
    "     accuracy = nltk.classify.accuracy(classifier, features[train_count:])\n",
    "     print(F\"{accuracy:.2%} - {name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ali-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
